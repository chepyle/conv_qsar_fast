{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `conv_qsar_fast` model with Hansen Ames data set [(Hansen, K. et al., 2009)](https://doi.org/10.1021/ci900161g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export KERAS_BACKEND='theano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from conv_qsar_fast.utils.parsing import input_to_bool\n",
    "from conv_qsar_fast.utils.parse_cfg import read_config\n",
    "import conv_qsar_fast.utils.reset_layers as reset_layers\n",
    "import rdkit.Chem as Chem\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from conv_qsar_fast.main.core import build_model, train_model, save_model\n",
    "from conv_qsar_fast.main.test import test_model, test_embeddings_demo\n",
    "from conv_qsar_fast.main.data import get_data_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_file='./conv_qsar_fast/inputs/hansen-Ames.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load settings\n",
    "config = read_config(config_file)\n",
    "\n",
    "# Get model label\n",
    "try:\n",
    "    fpath = config['IO']['model_fpath']\n",
    "except KeyError:\n",
    "    print('Must specify model_fpath in IO in config')\n",
    "    quit(1)\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "### DEFINE DATA \n",
    "###################################################################################\n",
    "\n",
    "data_kwargs = config['DATA']\n",
    "if '__name__' in data_kwargs:\n",
    "    del data_kwargs['__name__'] #  from configparser\n",
    "if 'batch_size' in config['TRAINING']:\n",
    "    data_kwargs['batch_size'] = int(config['TRAINING']['batch_size'])\n",
    "if 'use_fp' in config['ARCHITECTURE']:\n",
    "    data_kwargs['use_fp'] = config['ARCHITECTURE']['use_fp']\n",
    "if 'shuffle_seed' in data_kwargs:\n",
    "    data_kwargs['shuffle_seed'] = int(data_kwargs['shuffle_seed'])\n",
    "else:\n",
    "    data_kwargs['shuffle_seed'] = int(time.time())\n",
    "if 'truncate_to' in data_kwargs:\n",
    "    data_kwargs['truncate_to'] = int(data_kwargs['truncate_to'])\n",
    "if 'training_ratio' in data_kwargs:\n",
    "    data_kwargs['training_ratio'] = float(data_kwargs['training_ratio'])\n",
    "if 'molecular_attributes' in data_kwargs: \n",
    "    data_kwargs['molecular_attributes'] = input_to_bool(data_kwargs['molecular_attributes'])\n",
    "\n",
    "if 'cv_folds' in data_kwargs:\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(fpath))\n",
    "    except: # folder exists\n",
    "        pass\n",
    "    if '<this_fold>' in data_kwargs['cv_folds']:\n",
    "        cv_folds = data_kwargs['cv_folds']\n",
    "        total_folds = int(cv_folds.split('/')[1])\n",
    "        all_cv_folds = ['{}/{}'.format(i + 1, total_folds) for i in range(total_folds)]\n",
    "    else:\n",
    "        all_cv_folds = [data_kwargs['cv_folds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:130: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = \"d{} multiply atom contribs and adj mat\".format(d)\n",
      "/home/jak/miniconda3/envs/deepRxn3/lib/python3.6/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:149: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = 'd{} combine atom and bond contributions to new atom features'.format(d),\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:162: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  FPs = merge(output_contribs, mode = 'sum', name = 'pool across depths')\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:199: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[/feature ..., outputs=[sigmoid.0...)`\n",
      "  output = [ypred])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...built untrained model\n",
      "Using CV fold 1/5\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "**** DUPLICATE ENTRY ****\n",
      "[N-]=[N+]=NCCC(N)C(=O)O\n",
      "Failed to generate graph for NC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NC(COC(=O)\\C=N/#N)C(=O)O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for smiles, y: class\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for O=C1NC(=O)\\C(=N/#N)\\C=N1 , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NNC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Total of 6505 mols\n",
      "Split data into 5 folds\n",
      "...using fold 1\n",
      "Total training: 5204\n",
      "Total validation: 0\n",
      "Total testing: 1301\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 5204\n",
      "# validation: 1301\n",
      "# testing: 0\n",
      "...training model\n",
      "5204 to train on\n",
      "1301 to validate on\n",
      "1301 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.6900123357772827\tval_loss: 0.660118043422699\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.6245699524879456\tval_loss: 0.5969034433364868\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.6050261855125427\tval_loss: 0.565312385559082\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.5869804620742798\tval_loss: 0.5809115767478943\n",
      "1 epochs without val_loss progress\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.5728516578674316\tval_loss: 0.5492810606956482\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.558652400970459\tval_loss: 0.5705446600914001\n",
      "1 epochs without val_loss progress\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.5500072240829468\tval_loss: 0.5327261686325073\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.5432099103927612\tval_loss: 0.5210554599761963\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.5366670489311218\tval_loss: 0.5126745104789734\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.5342884063720703\tval_loss: 0.5130038261413574\n",
      "1 epochs without val_loss progress\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.5284276604652405\tval_loss: 0.5277228355407715\n",
      "2 epochs without val_loss progress\n",
      "Epoch 12/25, lr = 1.0\n",
      "loss: 0.5241422653198242\tval_loss: 0.6518213152885437\n",
      "3 epochs without val_loss progress\n",
      "Epoch 13/25, lr = 1.0\n",
      "loss: 0.521751344203949\tval_loss: 0.5107470750808716\n",
      "Epoch 14/25, lr = 1.0\n",
      "loss: 0.5180017352104187\tval_loss: 0.5016866326332092\n",
      "Epoch 15/25, lr = 1.0\n",
      "loss: 0.5143318176269531\tval_loss: 0.5081228613853455\n",
      "1 epochs without val_loss progress\n",
      "Epoch 16/25, lr = 1.0\n",
      "loss: 0.5070551037788391\tval_loss: 0.5036635994911194\n",
      "2 epochs without val_loss progress\n",
      "Epoch 17/25, lr = 1.0\n",
      "loss: 0.5046762228012085\tval_loss: 0.5041353106498718\n",
      "3 epochs without val_loss progress\n",
      "Epoch 18/25, lr = 1.0\n",
      "loss: 0.5043909549713135\tval_loss: 0.513024628162384\n",
      "4 epochs without val_loss progress\n",
      "Epoch 19/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5204 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.498638778924942\tval_loss: 0.5173741579055786\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-09 00:38:24.626328\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/hansen-Ames/fold1.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5204/5204 [00:14<00:00, 365.28it/s]\n",
      "100%|██████████| 1301/1301 [00:03<00:00, 429.52it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "  AUC = 0.8587039280473991\n",
      "  mse = 0.15828662369444696, mae = 0.3426138400246921\n",
      "test:\n",
      "  AUC = 0.8302915388402833\n",
      "  mse = 0.1690138027724349, mae = 0.35347983048660403\n",
      "...tested model\n",
      "...building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:130: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = \"d{} multiply atom contribs and adj mat\".format(d)\n",
      "/home/jak/miniconda3/envs/deepRxn3/lib/python3.6/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:149: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = 'd{} combine atom and bond contributions to new atom features'.format(d),\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:162: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  FPs = merge(output_contribs, mode = 'sum', name = 'pool across depths')\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:199: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[/feature ..., outputs=[sigmoid.0...)`\n",
      "  output = [ypred])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...built untrained model\n",
      "Using CV fold 2/5\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "**** DUPLICATE ENTRY ****\n",
      "[N-]=[N+]=NCCC(N)C(=O)O\n",
      "Failed to generate graph for NC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NC(COC(=O)\\C=N/#N)C(=O)O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for smiles, y: class\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for O=C1NC(=O)\\C(=N/#N)\\C=N1 , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NNC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Total of 6505 mols\n",
      "Split data into 5 folds\n",
      "...using fold 2\n",
      "Total training: 5204\n",
      "Total validation: 0\n",
      "Total testing: 1301\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 5204\n",
      "# validation: 1301\n",
      "# testing: 0\n",
      "...training model\n",
      "5204 to train on\n",
      "1301 to validate on\n",
      "1301 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.6840450167655945\tval_loss: 0.6683321595191956\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.6208721995353699\tval_loss: 0.6006121635437012\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.5922549962997437\tval_loss: 0.5728216171264648\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.5770829916000366\tval_loss: 0.5458649396896362\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.5642882585525513\tval_loss: 0.5269690155982971\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.5464317798614502\tval_loss: 0.550014317035675\n",
      "1 epochs without val_loss progress\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.5437898635864258\tval_loss: 0.5402669906616211\n",
      "2 epochs without val_loss progress\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.5355909466743469\tval_loss: 0.5470857620239258\n",
      "3 epochs without val_loss progress\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.5283739566802979\tval_loss: 0.5323512554168701\n",
      "4 epochs without val_loss progress\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.5263513326644897\tval_loss: 0.5122953057289124\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.5192278027534485\tval_loss: 0.5174758434295654\n",
      "1 epochs without val_loss progress\n",
      "Epoch 12/25, lr = 1.0\n",
      "loss: 0.5192678570747375\tval_loss: 0.5962958335876465\n",
      "2 epochs without val_loss progress\n",
      "Epoch 13/25, lr = 1.0\n",
      "loss: 0.51265949010849\tval_loss: 0.522702693939209\n",
      "3 epochs without val_loss progress\n",
      "Epoch 14/25, lr = 1.0\n",
      "loss: 0.5105533003807068\tval_loss: 0.5929332971572876\n",
      "4 epochs without val_loss progress\n",
      "Epoch 15/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5204 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5097170472145081\tval_loss: 0.5798339247703552\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-09 01:04:29.641791\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/hansen-Ames/fold2.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5204/5204 [00:15<00:00, 455.34it/s]\n",
      "100%|██████████| 1301/1301 [00:02<00:00, 473.50it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "  AUC = 0.8316375835220056\n",
      "  mse = 0.17948653623089345, mae = 0.29789900872355285\n",
      "test:\n",
      "  AUC = 0.8153213698434261\n",
      "  mse = 0.1913484318400043, mae = 0.3109090630191276\n",
      "...tested model\n",
      "...building model\n",
      "...built untrained model\n",
      "Using CV fold 3/5\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "**** DUPLICATE ENTRY ****\n",
      "[N-]=[N+]=NCCC(N)C(=O)O\n",
      "Failed to generate graph for NC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NC(COC(=O)\\C=N/#N)C(=O)O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for smiles, y: class\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for O=C1NC(=O)\\C(=N/#N)\\C=N1 , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NNC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Total of 6505 mols\n",
      "Split data into 5 folds\n",
      "...using fold 3\n",
      "Total training: 5204\n",
      "Total validation: 0\n",
      "Total testing: 1301\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 5204\n",
      "# validation: 1301\n",
      "# testing: 0\n",
      "...training model\n",
      "5204 to train on\n",
      "1301 to validate on\n",
      "1301 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.6883010268211365\tval_loss: 0.7502289414405823\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.6167374849319458\tval_loss: 0.6189999580383301\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.5851840376853943\tval_loss: 0.5659440755844116\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.5661577582359314\tval_loss: 0.5805552005767822\n",
      "1 epochs without val_loss progress\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.5536996126174927\tval_loss: 0.5649241209030151\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.5445023775100708\tval_loss: 0.5586434602737427\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.5385590195655823\tval_loss: 0.5302903056144714\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.5329171419143677\tval_loss: 0.5854148864746094\n",
      "1 epochs without val_loss progress\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.5368980765342712\tval_loss: 0.5264022946357727\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.5282393097877502\tval_loss: 0.5774595737457275\n",
      "1 epochs without val_loss progress\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.5211392641067505\tval_loss: 0.5387508273124695\n",
      "2 epochs without val_loss progress\n",
      "Epoch 12/25, lr = 1.0\n",
      "loss: 0.5240651965141296\tval_loss: 0.5131739377975464\n",
      "Epoch 13/25, lr = 1.0\n",
      "loss: 0.5212526917457581\tval_loss: 0.510855495929718\n",
      "Epoch 14/25, lr = 1.0\n",
      "loss: 0.5147185921669006\tval_loss: 0.5693020820617676\n",
      "1 epochs without val_loss progress\n",
      "Epoch 15/25, lr = 1.0\n",
      "loss: 0.5128291845321655\tval_loss: 0.5929095149040222\n",
      "2 epochs without val_loss progress\n",
      "Epoch 16/25, lr = 1.0\n",
      "loss: 0.5120711326599121\tval_loss: 0.5148801207542419\n",
      "3 epochs without val_loss progress\n",
      "Epoch 17/25, lr = 1.0\n",
      "loss: 0.5097002387046814\tval_loss: 0.5101385712623596\n",
      "Epoch 18/25, lr = 1.0\n",
      "loss: 0.5090263485908508\tval_loss: 0.4998220205307007\n",
      "Epoch 19/25, lr = 1.0\n",
      "loss: 0.508446216583252\tval_loss: 0.5297779440879822\n",
      "1 epochs without val_loss progress\n",
      "Epoch 20/25, lr = 1.0\n",
      "loss: 0.5006401538848877\tval_loss: 0.5094646215438843\n",
      "2 epochs without val_loss progress\n",
      "Epoch 21/25, lr = 1.0\n",
      "loss: 0.5007790327072144\tval_loss: 0.6156436800956726\n",
      "3 epochs without val_loss progress\n",
      "Epoch 22/25, lr = 1.0\n",
      "loss: 0.4959756135940552\tval_loss: 0.4975966513156891\n",
      "Epoch 23/25, lr = 1.0\n",
      "loss: 0.49519234895706177\tval_loss: 0.5046399235725403\n",
      "1 epochs without val_loss progress\n",
      "Epoch 24/25, lr = 1.0\n",
      "loss: 0.4952228367328644\tval_loss: 0.5705137848854065\n",
      "2 epochs without val_loss progress\n",
      "Epoch 25/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5204 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4891657531261444\tval_loss: 0.5028460621833801\n",
      "3 epochs without val_loss progress\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-09 01:44:40.639840\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/hansen-Ames/fold3.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5204/5204 [00:13<00:00, 388.89it/s]\n",
      "100%|██████████| 1301/1301 [00:02<00:00, 440.30it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "  AUC = 0.8596811846172137\n",
      "  mse = 0.1471399608573553, mae = 0.2895528671906532\n",
      "test:\n",
      "  AUC = 0.8394292738024052\n",
      "  mse = 0.16313136479820403, mae = 0.30630547801271757\n",
      "...tested model\n",
      "...building model\n",
      "...built untrained model\n",
      "Using CV fold 4/5\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "**** DUPLICATE ENTRY ****\n",
      "[N-]=[N+]=NCCC(N)C(=O)O\n",
      "Failed to generate graph for NC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NC(COC(=O)\\C=N/#N)C(=O)O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for smiles, y: class\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for O=C1NC(=O)\\C(=N/#N)\\C=N1 , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NNC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Total of 6505 mols\n",
      "Split data into 5 folds\n",
      "...using fold 4\n",
      "Total training: 5204\n",
      "Total validation: 0\n",
      "Total testing: 1301\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 5204\n",
      "# validation: 1301\n",
      "# testing: 0\n",
      "...training model\n",
      "5204 to train on\n",
      "1301 to validate on\n",
      "1301 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.6904873847961426\tval_loss: 0.6144559979438782\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.6138516068458557\tval_loss: 0.6120628714561462\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.5827135443687439\tval_loss: 0.5563036203384399\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.5674098134040833\tval_loss: 0.5766482949256897\n",
      "1 epochs without val_loss progress\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.5566847324371338\tval_loss: 0.6030917167663574\n",
      "2 epochs without val_loss progress\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.543040931224823\tval_loss: 0.5349839925765991\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.5274477005004883\tval_loss: 0.537311315536499\n",
      "1 epochs without val_loss progress\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.5253614187240601\tval_loss: 0.5232247710227966\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.5204155445098877\tval_loss: 0.521984338760376\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.5090460777282715\tval_loss: 0.5064352750778198\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.5053863525390625\tval_loss: 0.4993674159049988\n",
      "Epoch 12/25, lr = 1.0\n",
      "loss: 0.5003979206085205\tval_loss: 0.50998455286026\n",
      "1 epochs without val_loss progress\n",
      "Epoch 13/25, lr = 1.0\n",
      "loss: 0.4978131055831909\tval_loss: 0.5120440721511841\n",
      "2 epochs without val_loss progress\n",
      "Epoch 14/25, lr = 1.0\n",
      "loss: 0.49274304509162903\tval_loss: 0.5251703262329102\n",
      "3 epochs without val_loss progress\n",
      "Epoch 15/25, lr = 1.0\n",
      "loss: 0.49134689569473267\tval_loss: 0.5539076924324036\n",
      "4 epochs without val_loss progress\n",
      "Epoch 16/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5204 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4924558401107788\tval_loss: 0.5089186429977417\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-09 02:12:21.880313\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/hansen-Ames/fold4.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5204/5204 [00:15<00:00, 331.48it/s]\n",
      "100%|██████████| 1301/1301 [00:03<00:00, 365.45it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "  AUC = 0.8643174453265472\n",
      "  mse = 0.15384877652747578, mae = 0.34947153959683874\n",
      "test:\n",
      "  AUC = 0.8363024037366142\n",
      "  mse = 0.16447087511649094, mae = 0.35839185659286155\n",
      "...tested model\n",
      "...building model\n",
      "...built untrained model\n",
      "Using CV fold 5/5\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "**** DUPLICATE ENTRY ****\n",
      "[N-]=[N+]=NCCC(N)C(=O)O\n",
      "Failed to generate graph for NC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NC(COC(=O)\\C=N/#N)C(=O)O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for smiles, y: class\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for O=C1NC(=O)\\C(=N/#N)\\C=N1 , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Failed to generate graph for NNC(=O)CNC(=O)\\C=N\\#N , y: 1\n",
      "Python argument types in\n",
      "    rdkit.Chem.rdmolops.SanitizeMol(NoneType)\n",
      "did not match C++ signature:\n",
      "    SanitizeMol(RDKit::ROMol {lvalue} mol, unsigned long sanitizeOps=rdkit.Chem.rdmolops.SanitizeFlags.SANITIZE_ALL, bool catchErrors=False)\n",
      "Total of 6505 mols\n",
      "Split data into 5 folds\n",
      "...using fold 5\n",
      "Total training: 5204\n",
      "Total validation: 0\n",
      "Total testing: 1301\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 5204\n",
      "# validation: 1301\n",
      "# testing: 0\n",
      "...training model\n",
      "5204 to train on\n",
      "1301 to validate on\n",
      "1301 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.690193772315979\tval_loss: 0.6196342706680298\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.6201249957084656\tval_loss: 0.6220041513442993\n",
      "1 epochs without val_loss progress\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.5823206901550293\tval_loss: 0.5527966022491455\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.5644274353981018\tval_loss: 0.5475336909294128\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.5556750297546387\tval_loss: 0.5331463813781738\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.5464357733726501\tval_loss: 0.5523010492324829\n",
      "1 epochs without val_loss progress\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.5403457880020142\tval_loss: 0.5385414958000183\n",
      "2 epochs without val_loss progress\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.5355538725852966\tval_loss: 0.55862957239151\n",
      "3 epochs without val_loss progress\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.5318040251731873\tval_loss: 0.5571475028991699\n",
      "4 epochs without val_loss progress\n",
      "Epoch 10/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5204 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.526729166507721\tval_loss: 0.5466169118881226\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-09 02:30:14.137325\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/hansen-Ames/fold5.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5204/5204 [00:15<00:00, 335.16it/s]\n",
      "100%|██████████| 1301/1301 [00:03<00:00, 361.23it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "  AUC = 0.8399541111300979\n",
      "  mse = 0.17493107489763074, mae = 0.3604315434060676\n",
      "test:\n",
      "  AUC = 0.8133970719189558\n",
      "  mse = 0.18229093716523592, mae = 0.36581967144540234\n",
      "...tested model\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all folds\n",
    "ref_fpath = fpath\n",
    "for cv_fold in all_cv_folds:\n",
    "\n",
    "    ###################################################################################\n",
    "    ### BUILD MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    print('...building model')\n",
    "    try:\n",
    "        kwargs = config['ARCHITECTURE']\n",
    "        if '__name__' in kwargs: del kwargs['__name__'] #  from configparser\n",
    "        if 'batch_size' in config['TRAINING']:\n",
    "            kwargs['padding'] = int(config['TRAINING']['batch_size']) > 1\n",
    "        if 'embedding_size' in kwargs: \n",
    "            kwargs['embedding_size'] = int(kwargs['embedding_size'])\n",
    "        if 'hidden' in kwargs: \n",
    "            kwargs['hidden'] = int(kwargs['hidden'])\n",
    "        if 'hidden2' in kwargs:\n",
    "            kwargs['hidden2'] = int(kwargs['hidden2'])\n",
    "        if 'depth' in kwargs: \n",
    "            kwargs['depth'] = int(kwargs['depth'])\n",
    "        if 'scale_output' in kwargs: \n",
    "            kwargs['scale_output'] = float(kwargs['scale_output'])\n",
    "        if 'dr1' in kwargs:\n",
    "            kwargs['dr1'] = float(kwargs['dr1'])\n",
    "        if 'dr2' in kwargs:\n",
    "            kwargs['dr2'] = float(kwargs['dr2'])\n",
    "        if 'output_size' in kwargs:\n",
    "            kwargs['output_size'] = int(kwargs['output_size'])\n",
    "        if 'sum_after' in kwargs:\n",
    "            kwargs['sum_after'] = input_to_bool(kwargs['sum_after'])\n",
    "        if 'optimizer' in kwargs:\n",
    "            kwargs['optimizer'] = kwargs['optimizer']\n",
    "\n",
    "        if 'molecular_attributes' in config['DATA']:\n",
    "            kwargs['molecular_attributes'] = config['DATA']['molecular_attributes']\n",
    "\n",
    "        model = build_model(**kwargs)\n",
    "        print('...built untrained model')\n",
    "    except KeyboardInterrupt:\n",
    "        print('User cancelled model building')\n",
    "        quit(1)\n",
    "\n",
    "\n",
    "    print('Using CV fold {}'.format(cv_fold))\n",
    "    data_kwargs['cv_folds'] = cv_fold\n",
    "    fpath = ref_fpath.replace('<this_fold>', cv_fold.split('/')[0])\n",
    "    data = get_data_full(**data_kwargs)\n",
    "\n",
    "    \n",
    "\n",
    "###################################################################################\n",
    "    ### LOAD WEIGHTS?\n",
    "    ###################################################################################\n",
    "\n",
    "    if 'weights_fpath' in config['IO']:\n",
    "        weights_fpath = config['IO']['weights_fpath']\n",
    "    else:\n",
    "        weights_fpath = fpath + '.h5'\n",
    "\n",
    "    try:\n",
    "        use_old_weights = input_to_bool(config['IO']['use_existing_weights'])\n",
    "    except KeyError:\n",
    "        print('Must specify whether or not to use existing model weights')\n",
    "        quit(1)\n",
    "\n",
    "    if use_old_weights and os.path.isfile(weights_fpath):\n",
    "        model.load_weights(weights_fpath)\n",
    "        print('...loaded weight information')\n",
    "\n",
    "        # Reset final dense?\n",
    "        if 'reset_final' in config['IO']:\n",
    "            if config['IO']['reset_final'] in ['true', 'y', 'Yes', 'True', '1']:\n",
    "                layer = model.layers[-1]\n",
    "                layer.W.set_value((layer.init(layer.W.shape.eval()).eval()).astype(np.float32))\n",
    "                layer.b.set_value(np.zeros(layer.b.shape.eval(), dtype=np.float32))\n",
    "\n",
    "    elif use_old_weights and not os.path.isfile(weights_fpath):\n",
    "        print('Weights not found at specified path {}'.format(weights_fpath))\n",
    "        quit(1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ###################################################################################\n",
    "    ### CHECK FOR TESTING CONDITIONS\n",
    "    ###################################################################################\n",
    "\n",
    "    # Testing embeddings?\n",
    "    try:\n",
    "        if input_to_bool(config['TESTING']['test_embedding']):\n",
    "            test_embeddings_demo(model, fpath)\n",
    "            quit(1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    ###################################################################################\n",
    "    ### TRAIN THE MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    # Train model\n",
    "    try:\n",
    "        print('...training model')\n",
    "        kwargs = config['TRAINING']\n",
    "        if '__name__' in kwargs:\n",
    "            del kwargs['__name__'] #  from configparser\n",
    "        if 'nb_epoch' in kwargs:\n",
    "            kwargs['nb_epoch'] = int(kwargs['nb_epoch'])\n",
    "        if 'batch_size' in kwargs:\n",
    "            kwargs['batch_size'] = int(kwargs['batch_size'])\n",
    "        if 'patience' in kwargs:\n",
    "            kwargs['patience'] = int(kwargs['patience'])\n",
    "        (model, loss, val_loss) = train_model(model, data, **kwargs)\n",
    "        print('...trained model')\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    ###################################################################################\n",
    "    ### SAVE MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    # Get the current time\n",
    "    tstamp = datetime.datetime.utcnow().strftime('%m-%d-%Y_%H-%M')\n",
    "    print('...saving model')\n",
    "    save_model(model, \n",
    "        loss,\n",
    "        val_loss,\n",
    "        fpath = fpath,\n",
    "        config = config, \n",
    "        tstamp = tstamp)\n",
    "    print('...saved model')\n",
    "\n",
    "    ###################################################################################\n",
    "    ### TEST MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    print('...testing model')\n",
    "    data_withresiduals = test_model(model, data, fpath, tstamp = tstamp,\n",
    "        batch_size = int(config['TRAINING']['batch_size']))\n",
    "    print('...tested model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
