{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export KERAS_BACKEND=\"theano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from conv_qsar_fast.utils.parsing import input_to_bool\n",
    "from conv_qsar_fast.utils.parse_cfg import read_config\n",
    "import utils.reset_layers as reset_layers\n",
    "import rdkit.Chem as Chem\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from conv_qsar_fast.main.core import build_model, train_model, save_model\n",
    "from conv_qsar_fast.main.test import test_model, test_embeddings_demo\n",
    "from conv_qsar_fast.main.data import get_data_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_file='./conv_qsar_fast/inputs/tox21/tox21_ahr.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load settings\n",
    "config = read_config(config_file)\n",
    "\n",
    "# Get model label\n",
    "try:\n",
    "    fpath = config['IO']['model_fpath']\n",
    "except KeyError:\n",
    "    print('Must specify model_fpath in IO in config')\n",
    "    quit(1)\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "### DEFINE DATA \n",
    "###################################################################################\n",
    "\n",
    "data_kwargs = config['DATA']\n",
    "if '__name__' in data_kwargs:\n",
    "    del data_kwargs['__name__'] #  from configparser\n",
    "if 'batch_size' in config['TRAINING']:\n",
    "    data_kwargs['batch_size'] = int(config['TRAINING']['batch_size'])\n",
    "if 'use_fp' in config['ARCHITECTURE']:\n",
    "    data_kwargs['use_fp'] = config['ARCHITECTURE']['use_fp']\n",
    "if 'shuffle_seed' in data_kwargs:\n",
    "    data_kwargs['shuffle_seed'] = int(data_kwargs['shuffle_seed'])\n",
    "else:\n",
    "    data_kwargs['shuffle_seed'] = int(time.time())\n",
    "if 'truncate_to' in data_kwargs:\n",
    "    data_kwargs['truncate_to'] = int(data_kwargs['truncate_to'])\n",
    "if 'training_ratio' in data_kwargs:\n",
    "    data_kwargs['training_ratio'] = float(data_kwargs['training_ratio'])\n",
    "if 'molecular_attributes' in data_kwargs: \n",
    "    data_kwargs['molecular_attributes'] = input_to_bool(data_kwargs['molecular_attributes'])\n",
    "\n",
    "if 'cv_folds' in data_kwargs:\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(fpath))\n",
    "    except: # folder exists\n",
    "        pass\n",
    "    if '<this_fold>' in data_kwargs['cv_folds']:\n",
    "        cv_folds = data_kwargs['cv_folds']\n",
    "        total_folds = int(cv_folds.split('/')[1])\n",
    "        all_cv_folds = ['{}/{}'.format(i + 1, total_folds) for i in range(total_folds)]\n",
    "    else:\n",
    "        all_cv_folds = [data_kwargs['cv_folds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:130: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = \"d{} multiply atom contribs and adj mat\".format(d)\n",
      "/home/jak/miniconda3/envs/deepRxn3/lib/python3.6/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:149: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = 'd{} combine atom and bond contributions to new atom features'.format(d),\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:162: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  FPs = merge(output_contribs, mode = 'sum', name = 'pool across depths')\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:199: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[/feature ..., outputs=[sigmoid.0...)`\n",
      "  output = [ypred])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...built untrained model\n",
      "Using CV fold 1/5\n",
      "Assuming TOX21 data nr-ahr\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "Failed to generate graph for O.O.[Cl-].[Cl-].[Ba++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Hg++], y: 1\n",
      "\n",
      "Failed to generate graph for [K+].[I-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Ca++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cl-].[Fe+3], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cu++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Fe++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cd++], y: 1\n",
      "\n",
      "Failed to generate graph for [NH4+].[NH4+].[Cl-][Pt++]([Cl-])([Cl-])[Cl-], y: 0\n",
      "Sanitization error: Explicit valence for atom # 2 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Na+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Br-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[SnH2++], y: 0\n",
      "\n",
      "Failed to generate graph for O.O.O.O.O=C1O[Mg]2(OC(=O)C3=CC=CC=C3O2)OC4=CC=CC=C14, y: 0\n",
      "Sanitization error: Explicit valence for atom # 7 Mg, 4, is greater than permitted\n",
      "Failed to generate graph for [Cl-][Pt]1([Cl-])NCCN1, y: 0\n",
      "Sanitization error: Explicit valence for atom # 0 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [NH4+].[NH4+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Total of 8154 mols\n",
      "Split data into 5 folds\n",
      "...using fold 1\n",
      "Total training: 6523\n",
      "Total validation: 0\n",
      "Total testing: 1631\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 6523\n",
      "# validation: 1631\n",
      "# testing: 0\n",
      "...training model\n",
      "6523 to train on\n",
      "1631 to validate on\n",
      "1631 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.3057902157306671\tval_loss: 0.21902327239513397\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.27857619524002075\tval_loss: 0.20429350435733795\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.2699524760246277\tval_loss: 0.21607758104801178\n",
      "1 epochs without val_loss progress\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.2649316191673279\tval_loss: 0.20726555585861206\n",
      "2 epochs without val_loss progress\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.2601673901081085\tval_loss: 0.2059248834848404\n",
      "3 epochs without val_loss progress\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.25757482647895813\tval_loss: 0.19652992486953735\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.25652554631233215\tval_loss: 0.19626359641551971\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.2531653940677643\tval_loss: 0.19839079678058624\n",
      "1 epochs without val_loss progress\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.25085026025772095\tval_loss: 0.2065632939338684\n",
      "2 epochs without val_loss progress\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.24975182116031647\tval_loss: 0.26228049397468567\n",
      "3 epochs without val_loss progress\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.24739454686641693\tval_loss: 0.20762786269187927\n",
      "4 epochs without val_loss progress\n",
      "Epoch 12/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6523 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2459268718957901\tval_loss: 0.20821163058280945\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-07 12:25:08.690275\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/tox21_test_ahr/fold1.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6523/6523 [00:18<00:00, 360.09it/s]\n",
      "100%|██████████| 1631/1631 [00:04<00:00, 403.99it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "No module named 'sklearn'\n",
      "test:\n",
      "No module named 'sklearn'\n",
      "...tested model\n",
      "...building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:130: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = \"d{} multiply atom contribs and adj mat\".format(d)\n",
      "/home/jak/miniconda3/envs/deepRxn3/lib/python3.6/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:149: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name = 'd{} combine atom and bond contributions to new atom features'.format(d),\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:162: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  FPs = merge(output_contribs, mode = 'sum', name = 'pool across depths')\n",
      "/home/jak/Dropbox/Python/conv_qsar_fast/conv_qsar_fast/main/core.py:199: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[/feature ..., outputs=[sigmoid.0...)`\n",
      "  output = [ypred])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...built untrained model\n",
      "Using CV fold 2/5\n",
      "Assuming TOX21 data nr-ahr\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "Failed to generate graph for O.O.[Cl-].[Cl-].[Ba++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Hg++], y: 1\n",
      "\n",
      "Failed to generate graph for [K+].[I-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Ca++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cl-].[Fe+3], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cu++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Fe++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cd++], y: 1\n",
      "\n",
      "Failed to generate graph for [NH4+].[NH4+].[Cl-][Pt++]([Cl-])([Cl-])[Cl-], y: 0\n",
      "Sanitization error: Explicit valence for atom # 2 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Na+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Br-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[SnH2++], y: 0\n",
      "\n",
      "Failed to generate graph for O.O.O.O.O=C1O[Mg]2(OC(=O)C3=CC=CC=C3O2)OC4=CC=CC=C14, y: 0\n",
      "Sanitization error: Explicit valence for atom # 7 Mg, 4, is greater than permitted\n",
      "Failed to generate graph for [Cl-][Pt]1([Cl-])NCCN1, y: 0\n",
      "Sanitization error: Explicit valence for atom # 0 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [NH4+].[NH4+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Total of 8154 mols\n",
      "Split data into 5 folds\n",
      "...using fold 2\n",
      "Total training: 6523\n",
      "Total validation: 0\n",
      "Total testing: 1631\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 6523\n",
      "# validation: 1631\n",
      "# testing: 0\n",
      "...training model\n",
      "6523 to train on\n",
      "1631 to validate on\n",
      "1631 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.2980753779411316\tval_loss: 0.3022017180919647\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.27037373185157776\tval_loss: 0.2704521119594574\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.25817427039146423\tval_loss: 0.2906593978404999\n",
      "1 epochs without val_loss progress\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.25480225682258606\tval_loss: 0.26040929555892944\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.24807079136371613\tval_loss: 0.2502370774745941\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.24661050736904144\tval_loss: 0.2549813985824585\n",
      "1 epochs without val_loss progress\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.24477408826351166\tval_loss: 0.24784351885318756\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.24359528720378876\tval_loss: 0.24149130284786224\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.24407067894935608\tval_loss: 0.24586701393127441\n",
      "1 epochs without val_loss progress\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.2422824501991272\tval_loss: 0.28707095980644226\n",
      "2 epochs without val_loss progress\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.240275576710701\tval_loss: 0.25399017333984375\n",
      "3 epochs without val_loss progress\n",
      "Epoch 12/25, lr = 1.0\n",
      "loss: 0.2387550324201584\tval_loss: 0.23292814195156097\n",
      "Epoch 13/25, lr = 1.0\n",
      "loss: 0.2361937016248703\tval_loss: 0.27804046869277954\n",
      "1 epochs without val_loss progress\n",
      "Epoch 14/25, lr = 1.0\n",
      "loss: 0.23566834628582\tval_loss: 0.2788001298904419\n",
      "2 epochs without val_loss progress\n",
      "Epoch 15/25, lr = 1.0\n",
      "loss: 0.23508691787719727\tval_loss: 0.24852359294891357\n",
      "3 epochs without val_loss progress\n",
      "Epoch 16/25, lr = 1.0\n",
      "loss: 0.2364812046289444\tval_loss: 0.26844480633735657\n",
      "4 epochs without val_loss progress\n",
      "Epoch 17/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6523 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.23540595173835754\tval_loss: 0.23429061472415924\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-07 12:38:16.884320\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/tox21_test_ahr/fold2.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6523/6523 [00:14<00:00, 457.41it/s]\n",
      "100%|██████████| 1631/1631 [00:03<00:00, 465.01it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "No module named 'sklearn'\n",
      "test:\n",
      "No module named 'sklearn'\n",
      "...tested model\n",
      "...building model\n",
      "...built untrained model\n",
      "Using CV fold 3/5\n",
      "Assuming TOX21 data nr-ahr\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "Failed to generate graph for O.O.[Cl-].[Cl-].[Ba++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Hg++], y: 1\n",
      "\n",
      "Failed to generate graph for [K+].[I-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Ca++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cl-].[Fe+3], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cu++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Fe++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cd++], y: 1\n",
      "\n",
      "Failed to generate graph for [NH4+].[NH4+].[Cl-][Pt++]([Cl-])([Cl-])[Cl-], y: 0\n",
      "Sanitization error: Explicit valence for atom # 2 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Na+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Br-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[SnH2++], y: 0\n",
      "\n",
      "Failed to generate graph for O.O.O.O.O=C1O[Mg]2(OC(=O)C3=CC=CC=C3O2)OC4=CC=CC=C14, y: 0\n",
      "Sanitization error: Explicit valence for atom # 7 Mg, 4, is greater than permitted\n",
      "Failed to generate graph for [Cl-][Pt]1([Cl-])NCCN1, y: 0\n",
      "Sanitization error: Explicit valence for atom # 0 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [NH4+].[NH4+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Total of 8154 mols\n",
      "Split data into 5 folds\n",
      "...using fold 3\n",
      "Total training: 6523\n",
      "Total validation: 0\n",
      "Total testing: 1631\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 6523\n",
      "# validation: 1631\n",
      "# testing: 0\n",
      "...training model\n",
      "6523 to train on\n",
      "1631 to validate on\n",
      "1631 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.29598504304885864\tval_loss: 0.28531092405319214\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.2731388509273529\tval_loss: 0.29132089018821716\n",
      "1 epochs without val_loss progress\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.26296693086624146\tval_loss: 0.29344791173934937\n",
      "2 epochs without val_loss progress\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.2577623426914215\tval_loss: 0.2687334418296814\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.25058048963546753\tval_loss: 0.28242677450180054\n",
      "1 epochs without val_loss progress\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.24926263093948364\tval_loss: 0.28969377279281616\n",
      "2 epochs without val_loss progress\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.2474895417690277\tval_loss: 0.26701799035072327\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.24430470168590546\tval_loss: 0.41344451904296875\n",
      "1 epochs without val_loss progress\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.24443207681179047\tval_loss: 0.2663414776325226\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.2406964749097824\tval_loss: 0.30569756031036377\n",
      "1 epochs without val_loss progress\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.24196192622184753\tval_loss: 0.3156496584415436\n",
      "2 epochs without val_loss progress\n",
      "Epoch 12/25, lr = 1.0\n",
      "loss: 0.23896729946136475\tval_loss: 0.25261473655700684\n",
      "Epoch 13/25, lr = 1.0\n",
      "loss: 0.23396554589271545\tval_loss: 0.27072805166244507\n",
      "1 epochs without val_loss progress\n",
      "Epoch 14/25, lr = 1.0\n",
      "loss: 0.23544612526893616\tval_loss: 0.2909550368785858\n",
      "2 epochs without val_loss progress\n",
      "Epoch 15/25, lr = 1.0\n",
      "loss: 0.23349526524543762\tval_loss: 0.2742650806903839\n",
      "3 epochs without val_loss progress\n",
      "Epoch 16/25, lr = 1.0\n",
      "loss: 0.233311265707016\tval_loss: 0.26570114493370056\n",
      "4 epochs without val_loss progress\n",
      "Epoch 17/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6523 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2329334020614624\tval_loss: 0.26553913950920105\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-07 12:52:20.533134\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/tox21_test_ahr/fold3.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6523/6523 [00:18<00:00, 361.55it/s]\n",
      "100%|██████████| 1631/1631 [00:04<00:00, 379.66it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "No module named 'sklearn'\n",
      "test:\n",
      "No module named 'sklearn'\n",
      "...tested model\n",
      "...building model\n",
      "...built untrained model\n",
      "Using CV fold 4/5\n",
      "Assuming TOX21 data nr-ahr\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "Failed to generate graph for O.O.[Cl-].[Cl-].[Ba++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Hg++], y: 1\n",
      "\n",
      "Failed to generate graph for [K+].[I-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Ca++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cl-].[Fe+3], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cu++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Fe++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cd++], y: 1\n",
      "\n",
      "Failed to generate graph for [NH4+].[NH4+].[Cl-][Pt++]([Cl-])([Cl-])[Cl-], y: 0\n",
      "Sanitization error: Explicit valence for atom # 2 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Na+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Br-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[SnH2++], y: 0\n",
      "\n",
      "Failed to generate graph for O.O.O.O.O=C1O[Mg]2(OC(=O)C3=CC=CC=C3O2)OC4=CC=CC=C14, y: 0\n",
      "Sanitization error: Explicit valence for atom # 7 Mg, 4, is greater than permitted\n",
      "Failed to generate graph for [Cl-][Pt]1([Cl-])NCCN1, y: 0\n",
      "Sanitization error: Explicit valence for atom # 0 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [NH4+].[NH4+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Total of 8154 mols\n",
      "Split data into 5 folds\n",
      "...using fold 4\n",
      "Total training: 6523\n",
      "Total validation: 0\n",
      "Total testing: 1631\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 6523\n",
      "# validation: 1631\n",
      "# testing: 0\n",
      "...training model\n",
      "6523 to train on\n",
      "1631 to validate on\n",
      "1631 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.30368250608444214\tval_loss: 0.25114676356315613\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.27899637818336487\tval_loss: 0.2593332827091217\n",
      "1 epochs without val_loss progress\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.2707396447658539\tval_loss: 0.2574831247329712\n",
      "2 epochs without val_loss progress\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.26555174589157104\tval_loss: 0.2333042025566101\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.26058652997016907\tval_loss: 0.24038353562355042\n",
      "1 epochs without val_loss progress\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.2565157413482666\tval_loss: 0.225746288895607\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.25264212489128113\tval_loss: 0.23253093659877777\n",
      "1 epochs without val_loss progress\n",
      "Epoch 8/25, lr = 1.0\n",
      "loss: 0.2512367367744446\tval_loss: 0.22328133881092072\n",
      "Epoch 9/25, lr = 1.0\n",
      "loss: 0.250713586807251\tval_loss: 0.2512200176715851\n",
      "1 epochs without val_loss progress\n",
      "Epoch 10/25, lr = 1.0\n",
      "loss: 0.2485780417919159\tval_loss: 0.2242717295885086\n",
      "2 epochs without val_loss progress\n",
      "Epoch 11/25, lr = 1.0\n",
      "loss: 0.24763387441635132\tval_loss: 0.24170835316181183\n",
      "3 epochs without val_loss progress\n",
      "Epoch 12/25, lr = 1.0\n",
      "loss: 0.2449258416891098\tval_loss: 0.2288583368062973\n",
      "4 epochs without val_loss progress\n",
      "Epoch 13/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6523 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2416587620973587\tval_loss: 0.2243814915418625\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-07 13:03:37.195550\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/tox21_test_ahr/fold4.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6523/6523 [00:17<00:00, 365.34it/s]\n",
      "100%|██████████| 1631/1631 [00:04<00:00, 400.45it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "No module named 'sklearn'\n",
      "test:\n",
      "No module named 'sklearn'\n",
      "...tested model\n",
      "...building model\n",
      "...built untrained model\n",
      "Using CV fold 5/5\n",
      "Assuming TOX21 data nr-ahr\n",
      "reading data...\n",
      "done\n",
      "processing data...\n",
      "Failed to generate graph for O.O.[Cl-].[Cl-].[Ba++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Hg++], y: 1\n",
      "\n",
      "Failed to generate graph for [K+].[I-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Ca++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cl-].[Fe+3], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cu++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Fe++], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[Cd++], y: 1\n",
      "\n",
      "Failed to generate graph for [NH4+].[NH4+].[Cl-][Pt++]([Cl-])([Cl-])[Cl-], y: 0\n",
      "Sanitization error: Explicit valence for atom # 2 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Na+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Failed to generate graph for [Na+].[Br-], y: 0\n",
      "\n",
      "Failed to generate graph for [Cl-].[Cl-].[SnH2++], y: 0\n",
      "\n",
      "Failed to generate graph for O.O.O.O.O=C1O[Mg]2(OC(=O)C3=CC=CC=C3O2)OC4=CC=CC=C14, y: 0\n",
      "Sanitization error: Explicit valence for atom # 7 Mg, 4, is greater than permitted\n",
      "Failed to generate graph for [Cl-][Pt]1([Cl-])NCCN1, y: 0\n",
      "Sanitization error: Explicit valence for atom # 0 Cl, 2, is greater than permitted\n",
      "Failed to generate graph for [NH4+].[NH4+].F[Si--](F)(F)(F)(F)F, y: 0\n",
      "Sanitization error: Explicit valence for atom # 3 Si, 8, is greater than permitted\n",
      "Total of 8154 mols\n",
      "Split data into 5 folds\n",
      "...using fold 5\n",
      "Total training: 6524\n",
      "Total validation: 0\n",
      "Total testing: 1630\n",
      "AFTER MERGING DATASETS...\n",
      "# training: 6524\n",
      "# validation: 1630\n",
      "# testing: 0\n",
      "...training model\n",
      "6524 to train on\n",
      "1630 to validate on\n",
      "1630 to test on\n",
      "Epoch 1/25, lr = 1.0\n",
      "loss: 0.30087581276893616\tval_loss: 0.26046252250671387\n",
      "Epoch 2/25, lr = 1.0\n",
      "loss: 0.27255839109420776\tval_loss: 0.3117504417896271\n",
      "1 epochs without val_loss progress\n",
      "Epoch 3/25, lr = 1.0\n",
      "loss: 0.259287565946579\tval_loss: 0.24671685695648193\n",
      "Epoch 4/25, lr = 1.0\n",
      "loss: 0.25637897849082947\tval_loss: 0.27691224217414856\n",
      "1 epochs without val_loss progress\n",
      "Epoch 5/25, lr = 1.0\n",
      "loss: 0.25195834040641785\tval_loss: 0.29408735036849976\n",
      "2 epochs without val_loss progress\n",
      "Epoch 6/25, lr = 1.0\n",
      "loss: 0.24832308292388916\tval_loss: 0.3451586663722992\n",
      "3 epochs without val_loss progress\n",
      "Epoch 7/25, lr = 1.0\n",
      "loss: 0.2457754909992218\tval_loss: 0.30117231607437134\n",
      "4 epochs without val_loss progress\n",
      "Epoch 8/25, lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6524 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.24133722484111786\tval_loss: 0.25836968421936035\n",
      "5 epochs without val_loss progress\n",
      "stopping early!\n",
      "...trained model\n",
      "...saving model\n",
      "...saved structural information\n",
      "...saved weights\n",
      "trained at 2017-09-07 13:10:30.003201\n",
      "...saved history\n",
      "...saved model to conv_qsar_fast/models/tox21_test_ahr/fold5.[json, h5, png, info]\n",
      "...saved model\n",
      "...testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6524/6524 [00:14<00:00, 442.38it/s]\n",
      "100%|██████████| 1630/1630 [00:03<00:00, 495.97it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "No module named 'sklearn'\n",
      "test:\n",
      "No module named 'sklearn'\n",
      "...tested model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all folds\n",
    "ref_fpath = fpath\n",
    "for cv_fold in all_cv_folds:\n",
    "\n",
    "    ###################################################################################\n",
    "    ### BUILD MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    print('...building model')\n",
    "    try:\n",
    "        kwargs = config['ARCHITECTURE']\n",
    "        if '__name__' in kwargs: del kwargs['__name__'] #  from configparser\n",
    "        if 'batch_size' in config['TRAINING']:\n",
    "            kwargs['padding'] = int(config['TRAINING']['batch_size']) > 1\n",
    "        if 'embedding_size' in kwargs: \n",
    "            kwargs['embedding_size'] = int(kwargs['embedding_size'])\n",
    "        if 'hidden' in kwargs: \n",
    "            kwargs['hidden'] = int(kwargs['hidden'])\n",
    "        if 'hidden2' in kwargs:\n",
    "            kwargs['hidden2'] = int(kwargs['hidden2'])\n",
    "        if 'depth' in kwargs: \n",
    "            kwargs['depth'] = int(kwargs['depth'])\n",
    "        if 'scale_output' in kwargs: \n",
    "            kwargs['scale_output'] = float(kwargs['scale_output'])\n",
    "        if 'dr1' in kwargs:\n",
    "            kwargs['dr1'] = float(kwargs['dr1'])\n",
    "        if 'dr2' in kwargs:\n",
    "            kwargs['dr2'] = float(kwargs['dr2'])\n",
    "        if 'output_size' in kwargs:\n",
    "            kwargs['output_size'] = int(kwargs['output_size'])\n",
    "        if 'sum_after' in kwargs:\n",
    "            kwargs['sum_after'] = input_to_bool(kwargs['sum_after'])\n",
    "        if 'optimizer' in kwargs:\n",
    "            kwargs['optimizer'] = kwargs['optimizer']\n",
    "\n",
    "        if 'molecular_attributes' in config['DATA']:\n",
    "            kwargs['molecular_attributes'] = config['DATA']['molecular_attributes']\n",
    "\n",
    "        model = build_model(**kwargs)\n",
    "        print('...built untrained model')\n",
    "    except KeyboardInterrupt:\n",
    "        print('User cancelled model building')\n",
    "        quit(1)\n",
    "\n",
    "\n",
    "    print('Using CV fold {}'.format(cv_fold))\n",
    "    data_kwargs['cv_folds'] = cv_fold\n",
    "    fpath = ref_fpath.replace('<this_fold>', cv_fold.split('/')[0])\n",
    "    data = get_data_full(**data_kwargs)\n",
    "\n",
    "    ###################################################################################\n",
    "    ### LOAD WEIGHTS?\n",
    "    ###################################################################################\n",
    "\n",
    "    if 'weights_fpath' in config['IO']:\n",
    "        weights_fpath = config['IO']['weights_fpath']\n",
    "    else:\n",
    "        weights_fpath = fpath + '.h5'\n",
    "\n",
    "    try:\n",
    "        use_old_weights = input_to_bool(config['IO']['use_existing_weights'])\n",
    "    except KeyError:\n",
    "        print('Must specify whether or not to use existing model weights')\n",
    "        quit(1)\n",
    "\n",
    "    if use_old_weights and os.path.isfile(weights_fpath):\n",
    "        model.load_weights(weights_fpath)\n",
    "        print('...loaded weight information')\n",
    "\n",
    "        # Reset final dense?\n",
    "        if 'reset_final' in config['IO']:\n",
    "            if config['IO']['reset_final'] in ['true', 'y', 'Yes', 'True', '1']:\n",
    "                layer = model.layers[-1]\n",
    "                layer.W.set_value((layer.init(layer.W.shape.eval()).eval()).astype(np.float32))\n",
    "                layer.b.set_value(np.zeros(layer.b.shape.eval(), dtype=np.float32))\n",
    "\n",
    "    elif use_old_weights and not os.path.isfile(weights_fpath):\n",
    "        print('Weights not found at specified path {}'.format(weights_fpath))\n",
    "        quit(1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ###################################################################################\n",
    "    ### CHECK FOR TESTING CONDITIONS\n",
    "    ###################################################################################\n",
    "\n",
    "    # Testing embeddings?\n",
    "    try:\n",
    "        if input_to_bool(config['TESTING']['test_embedding']):\n",
    "            test_embeddings_demo(model, fpath)\n",
    "            quit(1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    ###################################################################################\n",
    "    ### TRAIN THE MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    # Train model\n",
    "    try:\n",
    "        print('...training model')\n",
    "        kwargs = config['TRAINING']\n",
    "        if '__name__' in kwargs:\n",
    "            del kwargs['__name__'] #  from configparser\n",
    "        if 'nb_epoch' in kwargs:\n",
    "            kwargs['nb_epoch'] = int(kwargs['nb_epoch'])\n",
    "        if 'batch_size' in kwargs:\n",
    "            kwargs['batch_size'] = int(kwargs['batch_size'])\n",
    "        if 'patience' in kwargs:\n",
    "            kwargs['patience'] = int(kwargs['patience'])\n",
    "        (model, loss, val_loss) = train_model(model, data, **kwargs)\n",
    "        print('...trained model')\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    ###################################################################################\n",
    "    ### SAVE MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    # Get the current time\n",
    "    tstamp = datetime.datetime.utcnow().strftime('%m-%d-%Y_%H-%M')\n",
    "    print('...saving model')\n",
    "    save_model(model, \n",
    "        loss,\n",
    "        val_loss,\n",
    "        fpath = fpath,\n",
    "        config = config, \n",
    "        tstamp = tstamp)\n",
    "    print('...saved model')\n",
    "\n",
    "    ###################################################################################\n",
    "    ### TEST MODEL\n",
    "    ###################################################################################\n",
    "\n",
    "    print('...testing model')\n",
    "    data_withresiduals = test_model(model, data, fpath, tstamp = tstamp,\n",
    "        batch_size = int(config['TRAINING']['batch_size']))\n",
    "    print('...tested model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
